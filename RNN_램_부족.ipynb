{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xJvL1mLVX3e9e9adoozrJezDCti01gM2",
      "authorship_tag": "ABX9TyOYf5F+ABVowHyz+bs5e2EA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferrry-ghsb/bigdata_6team/blob/main/RNN_%EB%9E%A8_%EB%B6%80%EC%A1%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x72volRVVBsB"
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "pd.options.display.max_rows = 50\n",
        "pd.options.display.max_columns = 40\n",
        "import numpy as np\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Mo8kW0VHl3"
      },
      "source": [
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Input, Dense, Activation, Flatten, Dropout\n",
        "from keras.layers import SimpleRNN, LSTM, GRU"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty3B1iJfWqUi"
      },
      "source": [
        "x_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/x_train.csv')\n",
        "x_valid = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/x_valid.csv')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/y_train.csv')\n",
        "y_valid = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/y_valid.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIISkXFPXSca"
      },
      "source": [
        "x_train = x_train[x_train.date >= '2016-01-01']\n",
        "x_valid = x_valid[x_valid.date <= '2016-06-12']\n",
        "y_train = x_train[x_train.date >= '2016-01-01']\n",
        "y_valid = x_valid[x_valid.date <= '2016-06-12']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4bC57vkXVD7"
      },
      "source": [
        "x_train = x_train.replace('-', '', regex=True).astype(int)\n",
        "x_valid = x_valid.replace('-', '', regex=True).astype(int)\n",
        "y_train = y_train.replace('-', '', regex=True).astype(int)\n",
        "y_valid = y_valid.replace('-', '', regex=True).astype(int)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktYE9cKNXXsi"
      },
      "source": [
        "scaler_X_tr = preprocessing.MinMaxScaler()\n",
        "scaler_Y_tr = preprocessing.MinMaxScaler()\n",
        "sequence = 34\n",
        "batch_size = 32\n",
        "epoch = 20\n",
        "verbose = 1\n",
        "dropout_ratio = 0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykWwOwn8XZsa",
        "outputId": "8c35d559-48f4-46a2-d3d4-2c1f7517320a"
      },
      "source": [
        "x_train['date']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1972674    20160101\n",
              "1972675    20160101\n",
              "1972676    20160101\n",
              "1972677    20160101\n",
              "1972678    20160101\n",
              "             ...   \n",
              "2443473    20160912\n",
              "2443474    20160912\n",
              "2443475    20160912\n",
              "2443476    20160912\n",
              "2443477    20160912\n",
              "Name: date, Length: 470804, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "ChE2VYnaXcFD",
        "outputId": "5a607a7e-48b1-4241-998b-6e33117dd66d"
      },
      "source": [
        "X_train_scaled = scaler_X_tr.fit_transform(x_train)\n",
        "Y_train_scaled = scaler_Y_tr.fit_transform(y_train)\n",
        "X_valid_scaled = scaler_X_tr.transform(x_valid)\n",
        "Y_valid_scaled = scaler_Y_tr.transform(y_valid)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
            "Feature names must be in the same order as they were in fit.\n",
            "\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3a185f522df7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_X_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mY_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_Y_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_valid_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_X_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mY_valid_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_Y_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         )\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m             )\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 286)) while a minimum of 1 is required."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4VH4xbDXetC"
      },
      "source": [
        "# X / Y split\n",
        "\n",
        "x_train, y_train = [], []\n",
        "for index in range(len(X_train_scaled) - sequence):\n",
        "    x_train.append(np.array(X_train_scaled[index: index + sequence]))\n",
        "    y_train.append(np.ravel(Y_train_scaled[index + sequence:index + sequence + 1]))\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "x_valid, y_valid = [], []\n",
        "for index in range(len(X_valid_scaled) - sequence):\n",
        "    x_valid.append(np.array(X_valid_scaled[index: index + sequence]))\n",
        "    y_valid.append(np.ravel(Y_valid_scaled[index + sequence:index + sequence + 1]))  \n",
        "x_valid, y_valid = np.array(x_valid), np.array(y_valid) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFwXdgaOXhSA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}